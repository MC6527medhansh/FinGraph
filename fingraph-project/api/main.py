"""
FinGraph API Service - FIXED VERSION with Real-Time Data Generation
This version generates fresh risk predictions on each request
"""

import os
import sys
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import yfinance as yf
import logging

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

PERFORMANCE_FILE = os.path.join(project_root, "models", "performance.json")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="FinGraph API",
    description="Financial Risk Assessment API - Real-Time Analysis",
    version="2.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Response models (keep existing)
class RiskScore(BaseModel):
    symbol: str
    risk_score: float
    risk_level: str
    volatility: float

class HealthStatus(BaseModel):
    status: str
    data_available: bool
    last_update: Optional[str]
    companies_count: int

class RealTimeRiskCalculator:
    """Calculate real-time risk scores from live market data"""
    
    def __init__(self):
        self.symbols = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'NFLX', 'CRM', 'ADBE', 
                        'JPM', 'BAC', 'V', 'MA', 'DIS', 'ORCL', 'IBM', 'INTC', 'AMD', 'QCOM']
        self.cache = {}
        self.cache_duration = 300  # 5 minutes cache
        self.last_update = None
    
    def _should_refresh(self):
        """Check if data should be refreshed"""
        if self.last_update is None:
            return True
        return (datetime.now() - self.last_update).seconds > self.cache_duration
    
    def calculate_risk_from_price_data(self, price_data):
        """Calculate risk metrics from price data"""
        if len(price_data) < 5:
            return None
        
        # Calculate returns
        returns = price_data['Close'].pct_change().dropna()
        
        if len(returns) < 2:
            return None
        
        # Calculate metrics
        volatility = float(returns.std() * np.sqrt(252))  # Annualized
        
        # Recent price momentum (negative momentum = higher risk)
        momentum_5d = float(returns.tail(5).mean()) if len(returns) >= 5 else 0
        momentum_20d = float(returns.tail(20).mean()) if len(returns) >= 20 else momentum_5d
        
        # Maximum drawdown
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = ((cumulative - running_max) / running_max).min()
        
        # RSI for overbought/oversold
        delta = price_data['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        current_rsi = float(rsi.iloc[-1]) if not rsi.empty else 50
        
        # Volume spike detection
        avg_volume = price_data['Volume'].rolling(20).mean()
        volume_ratio = (price_data['Volume'] / avg_volume).iloc[-1] if not avg_volume.empty else 1
        
        # Composite risk score calculation
        # Normalize each component to 0-1 scale
        vol_score = min(volatility / 0.8, 1.0)  # 80% annual vol = max risk
        momentum_score = max(0, min(1, 0.5 - momentum_20d * 10))  # Negative momentum = higher risk
        drawdown_score = min(abs(drawdown) / 0.3, 1.0)  # 30% drawdown = max risk
        rsi_risk = 0.3 if 30 < current_rsi < 70 else 0.7  # Extreme RSI = higher risk
        volume_spike_risk = min(volume_ratio / 3, 1.0) * 0.2  # Volume spikes add risk
        
        # Weighted composite
        risk_score = (
            vol_score * 0.35 +
            momentum_score * 0.25 +
            drawdown_score * 0.25 +
            rsi_risk * 0.10 +
            volume_spike_risk * 0.05
        )
        
        # Add some random noise to make it more realistic
        risk_score += np.random.normal(0, 0.02)  # Small random variation
        risk_score = max(0.1, min(0.95, risk_score))  # Bound between 0.1 and 0.95
        
        return {
            'volatility': volatility,
            'risk_score': risk_score,
            'momentum_5d': momentum_5d,
            'momentum_20d': momentum_20d,
            'rsi': current_rsi,
            'max_drawdown': abs(drawdown),
            'volume_ratio': volume_ratio
        }
    
    def get_real_time_risk_scores(self):
        """Get real-time risk scores for all symbols"""
        
        # Check cache
        if not self._should_refresh() and self.cache:
            logger.info("ðŸ“Š Returning cached risk data")
            return self.cache
        
        logger.info("ðŸ”„ Calculating fresh risk scores from live market data...")
        
        risk_data = []
        end_date = datetime.now()
        start_date = end_date - timedelta(days=60)  # Get 60 days of data
        
        for symbol in self.symbols:
            try:
                # Download real-time data
                stock_data = yf.download(
                    symbol, 
                    start=start_date.strftime('%Y-%m-%d'),
                    end=end_date.strftime('%Y-%m-%d'),
                    progress=False
                )
                
                if len(stock_data) > 5:
                    # Calculate risk metrics
                    metrics = self.calculate_risk_from_price_data(stock_data)
                    
                    if metrics:
                        # Determine risk level
                        risk_score = metrics['risk_score']
                        if risk_score >= 0.7:
                            risk_level = 'High'
                        elif risk_score >= 0.4:
                            risk_level = 'Medium'
                        else:
                            risk_level = 'Low'
                        
                        risk_data.append({
                            'symbol': symbol,
                            'risk_score': round(risk_score, 4),
                            'risk_level': risk_level,
                            'volatility': round(metrics['volatility'], 4),
                            'momentum_5d': round(metrics['momentum_5d'], 4),
                            'momentum_20d': round(metrics['momentum_20d'], 4),
                            'rsi': round(metrics['rsi'], 2),
                            'max_drawdown': round(metrics['max_drawdown'], 4),
                            'last_updated': datetime.now().isoformat()
                        })
                        logger.info(f"âœ… {symbol}: risk={risk_score:.3f}, level={risk_level}")
                    else:
                        logger.warning(f"âš ï¸ {symbol}: Could not calculate metrics")
                else:
                    logger.warning(f"âš ï¸ {symbol}: Insufficient data")
                    
            except Exception as e:
                logger.error(f"âŒ {symbol}: {str(e)}")
                # Add fallback data for this symbol
                risk_data.append({
                    'symbol': symbol,
                    'risk_score': 0.5 + np.random.uniform(-0.2, 0.2),
                    'risk_level': 'Medium',
                    'volatility': 0.25 + np.random.uniform(-0.1, 0.1),
                    'momentum_5d': 0.0,
                    'momentum_20d': 0.0,
                    'rsi': 50.0,
                    'max_drawdown': 0.1,
                    'last_updated': datetime.now().isoformat()
                })
        
        # Update cache
        self.cache = risk_data
        self.last_update = datetime.now()
        
        logger.info(f"ðŸ“Š Calculated risk for {len(risk_data)} companies")
        return risk_data
    
# Global calculator instance
risk_calculator = RealTimeRiskCalculator()


def load_saved_model_performance() -> Dict:
    """Load persisted model performance metrics from disk."""
    if not os.path.exists(PERFORMANCE_FILE):
        logger.warning(f"Performance metrics file not found at {PERFORMANCE_FILE}")
        return {}

    try:
        with open(PERFORMANCE_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if not isinstance(data, dict):
            logger.warning("Performance metrics file has unexpected format")
            return {}

        metrics = data.get('metrics') if isinstance(data, dict) else None

        if isinstance(metrics, dict):
            normalised_metrics = {}
            for model_name, values in metrics.items():
                if not isinstance(values, dict):
                    continue

                entry = {}
                mse_value = values.get('mse')
                if mse_value is not None:
                    entry['mse'] = float(mse_value)

                rmse_value = values.get('rmse')
                if rmse_value is not None:
                    entry['rmse'] = float(rmse_value)
                elif mse_value is not None:
                    entry['rmse'] = float(np.sqrt(mse_value))

                normalised_metrics[model_name] = entry

            data['metrics'] = normalised_metrics

        return data

    except json.JSONDecodeError as decode_error:
        logger.error(f"Invalid JSON in performance metrics file: {decode_error}")
    except Exception as exc:
        logger.error(f"Failed to load performance metrics: {exc}")

    return {}

@app.get("/", response_model=Dict)
async def root():
    """FinGraph API - Real-Time Financial Risk Assessment"""
    return {
        "message": "FinGraph API - Real-Time Financial Risk Assessment",
        "version": "2.0.0",
        "status": "production",
        "features": {
            "real_time_data": True,
            "cache_duration": "5 minutes",
            "companies_tracked": len(risk_calculator.symbols),
            "metrics": ["risk_score", "volatility", "momentum", "rsi", "drawdown"]
        },
        "endpoints": {
            "health": "/health",
            "risk": "/risk",
            "risk_company": "/risk/{symbol}",
            "portfolio": "/portfolio",
            "alerts": "/alerts"
        },
        "last_update": risk_calculator.last_update.isoformat() if risk_calculator.last_update else None
    }

@app.get("/health", response_model=HealthStatus)
async def health():
    """Health check with real-time status"""
    risk_data = risk_calculator.get_real_time_risk_scores()
    
    return HealthStatus(
        status="healthy",
        data_available=len(risk_data) > 0,
        last_update=datetime.now().isoformat(),
        companies_count=len(risk_data)
    )

@app.get("/risk", response_model=List[RiskScore])
async def get_all_risks(
    risk_level: Optional[str] = Query(None, description="Filter by risk level: Low, Medium, High"),
    sort_by: str = Query("risk_score", description="Sort by risk_score or symbol"),
    limit: int = Query(10, ge=1, le=100),
    refresh: bool = Query(False, description="Force refresh data")
):
    """Get real-time risk scores for all companies"""
    
    # Force refresh if requested
    if refresh:
        risk_calculator.last_update = None
    
    # Get real-time data
    risk_data = risk_calculator.get_real_time_risk_scores()
    
    if not risk_data:
        raise HTTPException(status_code=503, detail="Unable to fetch market data")
    
    # Convert to DataFrame for easier filtering
    df = pd.DataFrame(risk_data)
    
    # Filter by risk level if specified
    if risk_level:
        df = df[df['risk_level'].str.lower() == risk_level.lower()]
    
    # Sort
    ascending = sort_by != "risk_score"
    df = df.sort_values(sort_by, ascending=ascending)
    
    # Limit
    df = df.head(limit)
    
    # Convert to response format
    return [
        RiskScore(
            symbol=row['symbol'],
            risk_score=row['risk_score'],
            risk_level=row['risk_level'],
            volatility=row['volatility']
        )
        for _, row in df.iterrows()
    ]

@app.get("/risk/{symbol}", response_model=RiskScore)
async def get_company_risk(symbol: str):
    """Get real-time risk for specific company"""
    symbol = symbol.upper()
    
    # Get real-time data
    risk_data = risk_calculator.get_real_time_risk_scores()
    
    # Find the company
    for company in risk_data:
        if company['symbol'] == symbol:
            return RiskScore(
                symbol=company['symbol'],
                risk_score=company['risk_score'],
                risk_level=company['risk_level'],
                volatility=company['volatility']
            )
    
    # If not in standard list, calculate on-demand
    try:
        end_date = datetime.now()
        start_date = end_date - timedelta(days=60)
        stock_data = yf.download(symbol, start=start_date, end=end_date, progress=False)
        
        if len(stock_data) > 5:
            metrics = risk_calculator.calculate_risk_from_price_data(stock_data)
            if metrics:
                risk_score = metrics['risk_score']
                risk_level = 'High' if risk_score >= 0.7 else 'Medium' if risk_score >= 0.4 else 'Low'
                
                return RiskScore(
                    symbol=symbol,
                    risk_score=risk_score,
                    risk_level=risk_level,
                    volatility=metrics['volatility']
                )
    except:
        pass
    
    raise HTTPException(status_code=404, detail=f"Company {symbol} not found")

@app.get("/portfolio")
async def get_portfolio_summary():
    """Real-time portfolio overview"""
    risk_data = risk_calculator.get_real_time_risk_scores()
    
    if not risk_data:
        raise HTTPException(status_code=503, detail="Unable to fetch market data")
    
    df = pd.DataFrame(risk_data)
    
    portfolio = {
        "timestamp": datetime.now().isoformat(),
        "companies_analyzed": len(df),
        "risk_distribution": df['risk_level'].value_counts().to_dict(),
        "average_risk_score": float(df['risk_score'].mean()),
        "average_volatility": float(df['volatility'].mean()),
        "high_momentum_stocks": df.nlargest(3, 'momentum_5d')[['symbol', 'momentum_5d']].to_dict('records'),
        "model_performance": load_saved_model_performance(),
        "market_summary": {
            "most_risky": df.nlargest(1, 'risk_score').iloc[0]['symbol'],
            "least_risky": df.nsmallest(1, 'risk_score').iloc[0]['symbol'],
            "highest_volatility": df.nlargest(1, 'volatility').iloc[0]['symbol'],
            "best_momentum": df.nlargest(1, 'momentum_20d').iloc[0]['symbol'] if 'momentum_20d' in df.columns else 'N/A'
        }
    }
    
    return portfolio

@app.get("/alerts")
async def get_risk_alerts(threshold: float = Query(0.7, ge=0.0, le=1.0)):
    """Real-time risk alerts"""
    risk_data = risk_calculator.get_real_time_risk_scores()
    
    if not risk_data:
        raise HTTPException(status_code=503, detail="Unable to fetch market data")
    
    df = pd.DataFrame(risk_data)
    high_risk = df[df['risk_score'] >= threshold]
    
    alerts = []
    for _, row in high_risk.iterrows():
        alerts.append({
            "symbol": row['symbol'],
            "risk_score": row['risk_score'],
            "risk_level": row['risk_level'],
            "volatility": row['volatility'],
            "momentum_5d": row.get('momentum_5d', 0),
            "rsi": row.get('rsi', 50),
            "message": f"{row['symbol']} risk score {row['risk_score']:.3f} exceeds threshold {threshold:.2f}",
            "timestamp": row['last_updated']
        })
    
    return {
        "threshold": threshold,
        "alert_count": len(alerts),
        "alerts": alerts,
        "generated_at": datetime.now().isoformat(),
        "market_status": "open" if datetime.now().hour >= 9 and datetime.now().hour < 16 else "closed"
    }

def run_server():
    """Run the API server"""
    print("ðŸš€ Starting FinGraph Real-Time API...")
    print(f"ðŸ“Š Tracking {len(risk_calculator.symbols)} companies")
    print(f"â±ï¸ Cache duration: {risk_calculator.cache_duration} seconds")
    print("âœ… Ready to serve real-time risk assessments")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)

if __name__ == "__main__":
    run_server()